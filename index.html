<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Text to Speech Synthesizer</title>
    <style>
      * {
        box-sizing: border-box;
      }
      body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
      }
      .text-to-speech {
        display: flex;
        flex-direction: column;
        gap: 2rem;
        align-items: center;
        padding: 2rem;
      }
      h1 {
        font-size: 4rem;
        text-align: center;
      }
      .text-container {
        display: flex;
        flex-direction: column;
        justify-content: flex-start;
        align-items: center;
        gap: 1rem;
        width: 100%;
      }
      textarea {
        border: 3px solid #777;
        border-radius: 1rem;
        padding: 1rem;
        width: 100%;
        max-width: 600px;
        resize: none;
      }
      #speak {
        padding: 1rem;
        background-color: green;
        color: white;
        font-size: 1rem;
        font-weight: 700;
        border: none;
        border-radius: 0.5rem;
        cursor: pointer;
        width: 100%;
        max-width: 200px;
      }
      #speak:disabled {
        background-color: #cccccc;
        cursor: not-allowed;
      }
      audio {
        width: 100%;
        max-width: 600px;
      }

      /* Responsive Styles */
      @media (min-width: 768px) {
        .text-container {
          flex-direction: row;
          justify-content: center;
        }
        textarea {
          width: auto;
        }
        #speak {
          width: auto;
        }
      }
    </style>
  </head>
  <body>
    <div class="text-to-speech">
      <h1>Text to Speech Synthesizer</h1>
      <div class="text-container">
        <textarea
          id="textInput"
          rows="5"
          cols="40"
          placeholder="Enter text here..."
        ></textarea>
        <br />
        <button id="speak">Generate Speech</button>
      </div>
      <audio id="audioPlayer" controls></audio>
    </div>

    <script>
      let isPlaying = false;
      const audioMap = {
        a: "/sounds/alphabet/a/",
        b: "/sounds/alphabet/b/",
        c: "/sounds/alphabet/c/",
        d: "/sounds/alphabet/d/",
        e: "/sounds/alphabet/e/",
        f: "/sounds/alphabet/f/",
        g: "/sounds/alphabet/g/",
        h: "/sounds/alphabet/h/",
        i: "/sounds/alphabet/i/",
        j: "/sounds/alphabet/j/",
        k: "/sounds/alphabet/k/",
        l: "/sounds/alphabet/l/",
        m: "/sounds/alphabet/m/",
        n: "/sounds/alphabet/n/",
        o: "/sounds/alphabet/o/",
        p: "/sounds/alphabet/p/",
        q: "/sounds/alphabet/q/",
        r: "/sounds/alphabet/r/",
        s: "/sounds/alphabet/s/",
        t: "/sounds/alphabet/t/",
        u: "/sounds/alphabet/u/",
        v: "/sounds/alphabet/v/",
        w: "/sounds/alphabet/w/",
        x: "/sounds/alphabet/x/",
        y: "/sounds/alphabet/y/",
        z: "/sounds/alphabet/z/",
        // Add mappings for the remaining letters...
        apostrophe: "/sounds/punctuation marks/apostrophe/",
        asterisk: "/sounds/punctuation marks/asterisk/",
        at: "/sounds/punctuation marks/at the rate/",
        "close parentheses": "/sounds/punctuation marks/close parentheses/",
        "close quotation mark":
          "/sounds/punctuation marks/close quotation mark/",
        "close square bracket":
          "/sounds/punctuation marks/close square bracket/",
        colon: "/sounds/punctuation marks/colon/",
        comma: "/sounds/punctuation marks/comma/",
        copyright: "/sounds/punctuation marks/copyright/",
        dollar: "/sounds/punctuation marks/dollar/",
        ellipsis: "/sounds/punctuation marks/ellipsis/",
        "exclamation mark": "/sounds/punctuation marks/exclamation mark/",
        hashtag: "/sounds/punctuation marks/hashtag/",
        hyphen: "/sounds/punctuation marks/hyphen/",
        "open parentheses": "/sounds/punctuation marks/open parentheses/",
        "open quotation mark": "/sounds/punctuation marks/open quotation mark/",
        "open square bracket": "/sounds/punctuation marks/open square bracket/",
        percent: "/sounds/punctuation marks/percent/",
        period: "/sounds/punctuation marks/period/",
        "question mark": "/sounds/punctuation marks/question mark/",
        semicolon: "/sounds/punctuation marks/semicolon/",
        slash: "/sounds/punctuation marks/slash/",
        underscore: "/sounds/punctuation marks/underscore/",
        // Add mappings for other punctuation marks...
      };

      const punctuationMap = {
        "'": "apostrophe",
        "*": "asterisk",
        "@": "at",
        ")": "close parentheses",
        '"': "close quotation mark",
        "]": "close square bracket",
        ":": "colon",
        ",": "comma",
        "Â©": "copyright",
        $: "dollar",
        "...": "ellipsis",
        "!": "exclamation mark",
        "#": "hashtag",
        "-": "hyphen",
        "(": "open parentheses",
        '"': "open quotation mark",
        "[": "open square bracket",
        "%": "percent",
        ".": "period",
        "?": "question mark",
        ";": "semicolon",
        "/": "slash",
        _: "underscore",
        // Add mappings for other punctuation marks...
      };

      // Function to select a random variation (1 to 7)
      function getRandomVariation() {
        return Math.floor(Math.random() * 7) + 1;
      }

      // Function to convert a character to its corresponding audio file path
      function getAudioFilePath(char, variation) {
        const isLetter = /[a-zA-Z]/.test(char);
        const isPunctuation = /[^\w\s]/.test(char);

        if (isLetter) {
          const lowerChar = char.toLowerCase();
          const folderPath = audioMap[lowerChar];
          return folderPath
            ? `${folderPath}${lowerChar}${variation}.wav`
            : null;
        }

        if (isPunctuation) {
          const punctuationFolder = punctuationMap[char];
          if (punctuationFolder) {
            const folderPath = audioMap[punctuationFolder];
            return folderPath
              ? `${folderPath}${punctuationFolder}${variation}.wav`
              : null;
          }
        }

        return null;
      }

      // Fetch and decode the audio files into audio buffers
      async function fetchAudio(url) {
        const response = await fetch(url);
        const arrayBuffer = await response.arrayBuffer();
        return audioContext.decodeAudioData(arrayBuffer);
      }

      // Join all the audio buffers into one
      function joinAudioBuffers(buffers) {
        const totalLength = buffers.reduce(
          (acc, buffer) => acc + buffer.length,
          0
        );
        const joinedBuffer = audioContext.createBuffer(
          2,
          totalLength,
          audioContext.sampleRate
        );

        let offset = 0;
        buffers.forEach((buffer) => {
          for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
            joinedBuffer.copyToChannel(
              buffer.getChannelData(channel),
              channel,
              offset
            );
          }
          offset += buffer.length;
        });

        return joinedBuffer;
      }

      // Play the concatenated audio
      function playJoinedAudio(buffer) {
        const source = audioContext.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContext.destination);
        source.start(0);

        // Convert buffer to WAV format and create a Blob URL for the audio element
        const wavBuffer = bufferToWave(buffer, buffer.length);
        const blob = new Blob([wavBuffer], { type: "audio/wav" });
        const url = URL.createObjectURL(blob);

        document.getElementById("audioPlayer").src = url;
        source.onended = () => {
          isPlaying = false; // Reset the flag
          document.getElementById("speak").disabled = false; // Re-enable the button
        };
      }

      // Play audio files in sequence
      async function playTextAudio(text) {
        if (isPlaying) return;
        isPlaying = true;
        const chars = text.split(""); // Split text into characters
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let audioBufferList = [];
        let variation = getRandomVariation();
        for (let char of chars) {
          const audioFilePath = getAudioFilePath(char, variation);
          if (audioFilePath) {
            const audioBuffer = await fetchAudio(audioFilePath);
            audioBufferList.push(audioBuffer);
          }
        }

        const joinedBuffer = joinAudioBuffers(audioBufferList);
        playJoinedAudio(joinedBuffer);
      }

      // Add event listener to the button
      document.getElementById("speak").addEventListener("click", () => {
        document.getElementById("speak").disabled = true;
        const text = document.getElementById("textInput").value;
        if (text === "") {
          document.getElementById("speak").disabled = false;
          return;
        }
        playTextAudio(text);
      });

      // Convert buffer to WAV format
      function bufferToWave(abuffer, len) {
        const numOfChan = abuffer.numberOfChannels;
        const length = len * numOfChan * 2 + 44;
        const buffer = new ArrayBuffer(length);
        const view = new DataView(buffer);
        const channels = [];
        let offset = 0;
        let pos = 0;

        // Write WAVE header
        setUint32(0x46464952); // "RIFF"
        setUint32(length - 8); // file length - 8
        setUint32(0x45564157); // "WAVE"

        setUint32(0x20746d66); // "fmt " chunk
        setUint32(16); // length = 16
        setUint16(1); // PCM (uncompressed)
        setUint16(numOfChan);
        setUint32(abuffer.sampleRate);
        setUint32(abuffer.sampleRate * 2 * numOfChan); // avg. bytes/sec
        setUint16(numOfChan * 2); // block-align
        setUint16(16); // 16-bit (hardcoded)

        setUint32(0x61746164); // "data" - chunk
        setUint32(length - pos - 4); // chunk length

        // Write interleaved audio data
        for (let i = 0; i < abuffer.numberOfChannels; i++)
          channels.push(abuffer.getChannelData(i));

        while (pos < length) {
          for (let i = 0; i < numOfChan; i++) {
            const sample = Math.max(-1, Math.min(1, channels[i][offset]));
            const intSample =
              (sample < 0 ? sample * 0x8000 : sample * 0x7fff) | 0;
            view.setInt16(pos, intSample, true);
            pos += 2;
          }
          offset++;
        }

        function setUint16(data) {
          view.setUint16(pos, data, true);
          pos += 2;
        }

        function setUint32(data) {
          view.setUint32(pos, data, true);
          pos += 4;
        }

        return buffer;
      }
    </script>
  </body>
</html>
